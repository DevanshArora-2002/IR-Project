{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T11:13:44.670225Z",
     "iopub.status.busy": "2024-03-08T11:13:44.669819Z",
     "iopub.status.idle": "2024-03-08T11:13:45.181138Z",
     "shell.execute_reply": "2024-03-08T11:13:45.180372Z",
     "shell.execute_reply.started": "2024-03-08T11:13:44.670192Z"
    }
   },
   "outputs": [],
   "source": [
    "from document_extraction_ngram_bm25 import *\n",
    "from bs4 import BeautifulSoup\n",
    "import fitz  # PyMuPDF\n",
    "import pandas as pd\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "import shutil\n",
    "def get_text_from_page(page):\n",
    "    \"\"\"Extracts text from a single page.\"\"\"\n",
    "    html_text = page.get_text('html')\n",
    "    soup = BeautifulSoup(html_text, 'html.parser')\n",
    "    text_blocks = soup.find_all(['p', 'span'])  # Get paragraphs and span tags which may contain text.\n",
    "    page_text = \" \".join(block.text for block in text_blocks)\n",
    "    return page_text.strip()\n",
    "\n",
    "def combine_into_dataframe(book_path):\n",
    "    \"\"\"Combines all pages text into a pandas DataFrame.\"\"\"\n",
    "    doc = fitz.open(book_path)\n",
    "    doc_info = {\n",
    "        'page_no': [],\n",
    "        'text': []\n",
    "    }\n",
    "    for page_no in range(len(doc)):\n",
    "        print(f'Processing page: {page_no}')\n",
    "        page = doc[page_no]\n",
    "        page_text = get_text_from_page(page)\n",
    "        \n",
    "        doc_info['page_no'].append(page_no)\n",
    "        doc_info['text'].append(page_text)\n",
    "        \n",
    "    df = pd.DataFrame.from_dict(doc_info)\n",
    "    return df\n",
    "# Define a simple Document class if it's not already defined\n",
    "class Document:\n",
    "    def __init__(self, page_content, metadata=None):\n",
    "        self.page_content = page_content\n",
    "        self.metadata = metadata if metadata is not None else {}\n",
    "\n",
    "# Now, modify the split_text function to create Document objects from strings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter  # This import may need to be updated\n",
    "\n",
    "def split_text(doc_text):\n",
    "    # Create an instance of the RecursiveCharacterTextSplitter with the desired configuration\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=600,\n",
    "        chunk_overlap=100,\n",
    "        length_function=len,\n",
    "        add_start_index=True,\n",
    "    )\n",
    "    \n",
    "    # Create a Document object from the input text string\n",
    "    documents = [Document(doc_text)]\n",
    "    \n",
    "    # Now split the documents into chunks using the text_splitter\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    \n",
    "    # Here you can handle the chunks as needed, e.g., print the number of chunks\n",
    "    print(f\"Split 1 document into {len(chunks)} chunks.\")\n",
    "    \n",
    "    # Return the chunks if necessary\n",
    "    return chunks\n",
    "\n",
    "# Use the function with the text from the DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T11:14:08.004520Z",
     "iopub.status.busy": "2024-03-08T11:14:08.004179Z",
     "iopub.status.idle": "2024-03-08T11:14:08.009655Z",
     "shell.execute_reply": "2024-03-08T11:14:08.008608Z",
     "shell.execute_reply.started": "2024-03-08T11:14:08.004493Z"
    }
   },
   "outputs": [],
   "source": [
    "def prompt_generation(ranked_text,query):\n",
    "    context = \"\"\n",
    "    for i in range(len(ranked_text)):\n",
    "        context = f\"{i+1}: {ranked_text['text'].iloc[i]}\"\n",
    "    prompt = f\"\"\"Generate legal advice for {query} \n",
    "                using the following contexual information {context}\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T11:40:21.516821Z",
     "iopub.status.busy": "2024-03-08T11:40:21.515803Z",
     "iopub.status.idle": "2024-03-08T11:40:21.526143Z",
     "shell.execute_reply": "2024-03-08T11:40:21.525109Z",
     "shell.execute_reply.started": "2024-03-08T11:40:21.516776Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "def generate_text(prompt,tokenizer,model):\n",
    "    \"\"\"\n",
    "    Generate text from a pre-trained language model given a prompt and a model name.\n",
    "\n",
    "    Parameters:\n",
    "    prompt (str): The prompt text to feed to the language model.\n",
    "    model_name (str): The model identifier on Hugging Face's model hub.\n",
    "\n",
    "    Returns:\n",
    "    str: The text generated by the model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Encode the prompt text\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
    "    print(\"Done\")\n",
    "    # Generate text using the model\n",
    "    output = model.generate(\n",
    "    input_ids,\n",
    "    max_length=250,\n",
    "    max_new_tokens=250,\n",
    "    temperature=0.5,  # Adjust temperature for determinism\n",
    "    top_p=0.95,       # Narrow down while allowing some diversity\n",
    "    no_repeat_ngram_size=2  # Prevent repeating n-grams\n",
    "    )\n",
    "    \n",
    "    # Decode the generated text\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    cleaned_text = generated_text.split(\"Generate legal advice for\")[1].strip()  # Simplified example\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T11:14:22.756219Z",
     "iopub.status.busy": "2024-03-08T11:14:22.755631Z",
     "iopub.status.idle": "2024-03-08T11:14:22.762342Z",
     "shell.execute_reply": "2024-03-08T11:14:22.761491Z",
     "shell.execute_reply.started": "2024-03-08T11:14:22.756189Z"
    }
   },
   "outputs": [],
   "source": [
    "def chunking_process(book_df):\n",
    "    chunked_dict = {}\n",
    "    chunked_dict['text'] = []\n",
    "    for i in range(len(book_df)):\n",
    "        chunked_data = split_text(book_df['text'].iloc[i])\n",
    "        chunked_dict['text'].extend([page_data.page_content for page_data in chunked_data])\n",
    "    return pd.DataFrame.from_dict(chunked_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T11:14:35.009679Z",
     "iopub.status.busy": "2024-03-08T11:14:35.008764Z",
     "iopub.status.idle": "2024-03-08T11:23:22.157920Z",
     "shell.execute_reply": "2024-03-08T11:23:22.157015Z",
     "shell.execute_reply.started": "2024-03-08T11:14:35.009645Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c84baf00db4ae8a277335778933c51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/266 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c62a1f5cae341d598c8c995ad980a56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/14.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b0308d60b64d2d93b854c98229d799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/96.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ee929743f8c475fbf9b19ed06fd0e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/798 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cf9d27d62d44dab9597a7f587129d1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin.index.json:   0%|          | 0.00/31.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02988592b9a64763bb6b8d2a5a962f88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e66d2b483d9d43589e9d0df9a60ef5ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.91G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f33d7c42fb6e4f33beaf4838ac95b135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00002-of-00002.bin:   0%|          | 0.00/4.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efd058f7be574ced84b640ecc51611c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "model_name='tomrb/bettercallbloom-3b'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T11:23:32.068982Z",
     "iopub.status.busy": "2024-03-08T11:23:32.068163Z",
     "iopub.status.idle": "2024-03-08T11:23:32.137173Z",
     "shell.execute_reply": "2024-03-08T11:23:32.136264Z",
     "shell.execute_reply.started": "2024-03-08T11:23:32.068947Z"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T11:25:22.411227Z",
     "iopub.status.busy": "2024-03-08T11:25:22.410293Z",
     "iopub.status.idle": "2024-03-08T11:25:25.801417Z",
     "shell.execute_reply": "2024-03-08T11:25:25.800341Z",
     "shell.execute_reply.started": "2024-03-08T11:25:22.411191Z"
    }
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T11:44:58.538974Z",
     "iopub.status.busy": "2024-03-08T11:44:58.538279Z",
     "iopub.status.idle": "2024-03-08T11:45:06.941584Z",
     "shell.execute_reply": "2024-03-08T11:45:06.940576Z",
     "shell.execute_reply.started": "2024-03-08T11:44:58.538944Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page: 0\n",
      "Processing page: 1\n",
      "Processing page: 2\n",
      "Processing page: 3\n",
      "Processing page: 4\n",
      "Processing page: 5\n",
      "Processing page: 6\n",
      "Processing page: 7\n",
      "Split 1 document into 3 chunks.\n",
      "Split 1 document into 11 chunks.\n",
      "Split 1 document into 16 chunks.\n",
      "Split 1 document into 17 chunks.\n",
      "Split 1 document into 18 chunks.\n",
      "Split 1 document into 17 chunks.\n",
      "Split 1 document into 17 chunks.\n",
      "Split 1 document into 10 chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Both `max_new_tokens` (=250) and `max_length`(=250) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "book_path = '/kaggle/input/bookpdf/A2017-15_2.pdf'\n",
    "df = combine_into_dataframe(book_path)\n",
    "chunked_data = chunking_process(df)\n",
    "query = \"Is Service charge applicable over GST?\"\n",
    "top_results = calculate_bm25_scores(chunked_data,query,[10])\n",
    "prompt = prompt_generation(top_results,query)\n",
    "generated_text = generate_text(prompt,tokenizer,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T11:45:06.943814Z",
     "iopub.status.busy": "2024-03-08T11:45:06.943450Z",
     "iopub.status.idle": "2024-03-08T11:45:06.949040Z",
     "shell.execute_reply": "2024-03-08T11:45:06.947982Z",
     "shell.execute_reply.started": "2024-03-08T11:45:06.943781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate legal advice for Is Service charge applicable over GST? \n",
      "                using the following contexual information 109: (m) “State” means,––  ( m ) “State” means,––  (i) for the purposes of sections 3, 4, 5, 6 and 7 the States as defined under the Central Goods  ( i ) for the purposes of sections 3, 4, 5, 6 and 7 the States as defined under the Central Goods  and Services Tax Act; and  and Services Tax Act; and  (ii) for the purposes of sections 8, 9, 10, 11, 12, 13 and 14 the States as defined under the Central  ( ii ) for the purposes of sections 8, 9, 10, 11, 12, 13 and 14 the States as defined under the Central  Goods and Services Tax Act and the Union territories as defined under the Union Territories\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T11:45:06.950529Z",
     "iopub.status.busy": "2024-03-08T11:45:06.950164Z",
     "iopub.status.idle": "2024-03-08T11:45:06.959618Z",
     "shell.execute_reply": "2024-03-08T11:45:06.958524Z",
     "shell.execute_reply.started": "2024-03-08T11:45:06.950497Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Service charge applicable over GST? \n",
      "                using the following contexual information 109: (m) “State” means,––  ( m ) “State” means,––  (i) for the purposes of sections 3, 4, 5, 6 and 7 the States as defined under the Central Goods  ( i ) for the purposes of sections 3, 4, 5, 6 and 7 the States as defined under the Central Goods  and Services Tax Act; and  and Services Tax Act; and  (ii) for the purposes of sections 8, 9, 10, 11, 12, 13 and 14 the States as defined under the Central  ( ii ) for the purposes of sections 8, 9, 10, 11, 12, 13 and 14 the States as defined under the Central  Goods and Services Tax Act and the Union territories as defined under the Union Territories  goods and services tax Act, and (j) the territories under section 1 of the Customs ( j ) the Territories under Section 1  of Customs Acts, including the Northern Territory, the Australian Capital Territory,  the Tasmania, South Australia, Queensland, Western Australia and New  South Wales, as well as the Federal Territory of Tasmania; and \n",
      "\n",
      "Answer #1: IANAL, but I am a tax professional. I would say that the service charge is not applicable to you. You are not a service provider. The service tax is applicable only to service providers. So, you are a non-service provider and therefore not subject to the tax.Title: [CA] My friend's ex-wife is threatening to sue her for custody of their daughter.\n",
      "Question:My friend has a daughter with her ex. They have been divorced for a few years now, with the ex having primary custody. Recently, she has been having some issues with drug abuse and has had a rough time with it. She has also been in and out of jail for various reasons. Her daughter has recently been living with my friend for about a month, since her mother has gotten her back on her feet. My question is, is there any way that my\n"
     ]
    }
   ],
   "source": [
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T11:47:33.454340Z",
     "iopub.status.busy": "2024-03-08T11:47:33.453433Z",
     "iopub.status.idle": "2024-03-08T11:47:41.691002Z",
     "shell.execute_reply": "2024-03-08T11:47:41.690234Z",
     "shell.execute_reply.started": "2024-03-08T11:47:33.454307Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=250) and `max_length`(=250) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "query2 = \"How is revenue calculated over an year\"\n",
    "top_results2 = calculate_bm25_scores(chunked_data,query2,[10])\n",
    "prompt2 = prompt_generation(top_results2,query2)\n",
    "generated_text2 = generate_text(prompt2,tokenizer,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T11:47:48.036411Z",
     "iopub.status.busy": "2024-03-08T11:47:48.036049Z",
     "iopub.status.idle": "2024-03-08T11:47:48.041286Z",
     "shell.execute_reply": "2024-03-08T11:47:48.040351Z",
     "shell.execute_reply.started": "2024-03-08T11:47:48.036387Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate legal advice for How is revenue calculated over an year \n",
      "                using the following contexual information 109: (m) “State” means,––  ( m ) “State” means,––  (i) for the purposes of sections 3, 4, 5, 6 and 7 the States as defined under the Central Goods  ( i ) for the purposes of sections 3, 4, 5, 6 and 7 the States as defined under the Central Goods  and Services Tax Act; and  and Services Tax Act; and  (ii) for the purposes of sections 8, 9, 10, 11, 12, 13 and 14 the States as defined under the Central  ( ii ) for the purposes of sections 8, 9, 10, 11, 12, 13 and 14 the States as defined under the Central  Goods and Services Tax Act and the Union territories as defined under the Union Territories\n"
     ]
    }
   ],
   "source": [
    "print(prompt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T11:47:58.937860Z",
     "iopub.status.busy": "2024-03-08T11:47:58.936988Z",
     "iopub.status.idle": "2024-03-08T11:47:58.942355Z",
     "shell.execute_reply": "2024-03-08T11:47:58.941321Z",
     "shell.execute_reply.started": "2024-03-08T11:47:58.937827Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How is revenue calculated over an year \n",
      "                using the following contexual information 109: (m) “State” means,––  ( m ) “State” means,––  (i) for the purposes of sections 3, 4, 5, 6 and 7 the States as defined under the Central Goods  ( i ) for the purposes of sections 3, 4, 5, 6 and 7 the States as defined under the Central Goods  and Services Tax Act; and  and Services Tax Act; and  (ii) for the purposes of sections 8, 9, 10, 11, 12, 13 and 14 the States as defined under the Central  ( ii ) for the purposes of sections 8, 9, 10, 11, 12, 13 and 14 the States as defined under the Central  Goods and Services Tax Act and the Union territories as defined under the Union Territories  goods and services tax Act, and (iii) the Federal Territory of Fiji, the  Federal  Territory  of  Fiji,  the Federated States of Micronesia, Federally  independent  States  in  Micronesia, Solomon Islands, Vanuatu, New Zealand, Fiji and Papua New Guinea.”\n",
      "\n",
      "I am not sure if this is the right place to ask this question, but I am looking for some advice on how to proceed. I have been working for a company for about a year and a half. The company is based in the US and I work from home. My company pays me a salary and pays taxes on it. However, I also receive a commission for sales. This commission is calculated based on the sales I make. For example, if I sell a product for $500, then I get a $200 commission. If I do not sell the product, or if the sale is less than $400, my commission goes down to $150. So, for example if a sale was $300, it would be $75 in commission, $25 in salary, $50 in taxes, etc. Basically, this company has a system where they pay me based off of the amount of sales they make,\n"
     ]
    }
   ],
   "source": [
    "print(generated_text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T11:52:40.235083Z",
     "iopub.status.busy": "2024-03-08T11:52:40.234698Z",
     "iopub.status.idle": "2024-03-08T11:52:48.461119Z",
     "shell.execute_reply": "2024-03-08T11:52:48.460329Z",
     "shell.execute_reply.started": "2024-03-08T11:52:40.235053Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=250) and `max_length`(=250) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "query3 = \"My friend is refusing to return money what should I do?\"\n",
    "top_results3 = calculate_bm25_scores(chunked_data,query3,[10])\n",
    "prompt3 = prompt_generation(top_results3,query3)\n",
    "generated_text3 = generate_text(prompt3,tokenizer,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T11:52:48.462841Z",
     "iopub.status.busy": "2024-03-08T11:52:48.462555Z",
     "iopub.status.idle": "2024-03-08T11:52:48.467459Z",
     "shell.execute_reply": "2024-03-08T11:52:48.466563Z",
     "shell.execute_reply.started": "2024-03-08T11:52:48.462816Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate legal advice for My friend is refusing to return money what should I do? \n",
      "                using the following contexual information 109: (m) “State” means,––  ( m ) “State” means,––  (i) for the purposes of sections 3, 4, 5, 6 and 7 the States as defined under the Central Goods  ( i ) for the purposes of sections 3, 4, 5, 6 and 7 the States as defined under the Central Goods  and Services Tax Act; and  and Services Tax Act; and  (ii) for the purposes of sections 8, 9, 10, 11, 12, 13 and 14 the States as defined under the Central  ( ii ) for the purposes of sections 8, 9, 10, 11, 12, 13 and 14 the States as defined under the Central  Goods and Services Tax Act and the Union territories as defined under the Union Territories\n"
     ]
    }
   ],
   "source": [
    "print(prompt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T11:53:00.539492Z",
     "iopub.status.busy": "2024-03-08T11:53:00.539149Z",
     "iopub.status.idle": "2024-03-08T11:53:00.544526Z",
     "shell.execute_reply": "2024-03-08T11:53:00.543495Z",
     "shell.execute_reply.started": "2024-03-08T11:53:00.539468Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My friend is refusing to return money what should I do? \n",
      "                using the following contexual information 109: (m) “State” means,––  ( m ) “State” means,––  (i) for the purposes of sections 3, 4, 5, 6 and 7 the States as defined under the Central Goods  ( i ) for the purposes of sections 3, 4, 5, 6 and 7 the States as defined under the Central Goods  and Services Tax Act; and  and Services Tax Act; and  (ii) for the purposes of sections 8, 9, 10, 11, 12, 13 and 14 the States as defined under the Central  ( ii ) for the purposes of sections 8, 9, 10, 11, 12, 13 and 14 the States as defined under the Central  Goods and Services Tax Act and the Union territories as defined under the Union Territories  goods and services tax Act, and (j) the words “or any other State” in the definition of “goods” and “services”  in section 1 of the Act shall be replaced by the  words, “and any goods or services”, respectively, in order to ensure that the provisions of  the act are not affected by any changes in State laws or regulations.Answer #2: You can sue him in small claims court for your money.Title: [CA] My ex-girlfriend is threatening to sue me for emotional distress and slander. What can I expect?\n",
      "Question:I dated this girl for a year and a half. We broke up in May and she has been harassing me ever since. She has threatened to call the police on me, to have me arrested, etc. I have blocked her on everything and have not responded to any of her messages. Today she messaged me on Facebook and said that she was going to file a police report against me and that I was a danger to her and her family. This is all in response to me telling her that we were done and I would never contact her again. Is there anything I can do to protect myself from this? I am in California\n"
     ]
    }
   ],
   "source": [
    "print(generated_text3)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4561602,
     "sourceId": 7792497,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30665,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
